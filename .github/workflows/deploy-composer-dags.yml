name: Deploy Airflow DAGs to Cloud Composer

on:
  push:
    paths:
      - "dags/**" # Trigger the workflow only when files in the 'dags' folder are changed
    branches:
      - main      # Run for changes pushed to the 'main' branch
      - develop   # Run for changes pushed to the 'develop' branch

jobs:
  deploy-dags:
    runs-on: ubuntu-latest

    strategy:
      matrix:
        environment: [dev, prod] # Define environments
    env:
      GCP_PROJECT_ID_DEV: ${{ secrets.GCP_PROJECT_ID_DEV }}
      GCP_PROJECT_ID_PROD: ${{ secrets.GCP_PROJECT_ID_PROD }}
      COMPOSER_BUCKET_DEV: ${{ secrets.COMPOSER_BUCKET_DEV }}
      COMPOSER_BUCKET_PROD: ${{ secrets.COMPOSER_BUCKET_PROD }}

    steps:
      # Step 1: Checkout the code from the repository
      - name: Checkout code
        uses: actions/checkout@v3

      # Step 2: Set up Google Cloud SDK
      - name: Set up Google Cloud SDK
        uses: google-github-actions/setup-gcloud@v1
        with:
          project_id: ${{ matrix.environment == 'dev' && secrets.GCP_PROJECT_ID_DEV || secrets.GCP_PROJECT_ID_PROD }}
          service_account_key: ${{ secrets.GCP_SA_KEY }}

      # Step 3: Authenticate with Google Cloud
      - name: Authenticate with Google Cloud
        run: gcloud auth activate-service-account --key-file=${{ secrets.GCP_SA_KEY }}

      # Step 4: Upload DAGs to the appropriate Cloud Composer bucket
      - name: Upload DAGs to Cloud Composer
        env:
          COMPOSER_BUCKET: ${{ matrix.environment == 'dev' && secrets.COMPOSER_BUCKET_DEV || secrets.COMPOSER_BUCKET_PROD }}
        run: |
          gsutil -m rsync -r dags/ gs://${COMPOSER_BUCKET}/dags/
